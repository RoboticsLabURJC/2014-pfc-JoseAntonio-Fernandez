%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Plantilla de memoria en LaTeX para la ETSIT - Universidad Rey Juan Carlos
%%
%% Por Gregorio Robles <grex arroba gsyc.urjc.es>
%%     Grupo de Sistemás y Comunicaciones
%%     Escuela T\'ecnica Superior de Ingenieros de Telecomunicaci\'on
%%     Universidad Rey Juan Carlos
%% (muchas ideas tomadas de Internet, colegas del GSyC, antiguos alumnos...
%%  etc. Muchas gracias a todos)
%%
%% La \'ultima versi\'on de esta plantilla est\'a siempre disponible en:
%%     https://github.com/gregoriorobles/plantilla-memoria
%%
%% Para obtener PDF, ejecuta en la shell:
%%   make
%% (las im\'agenes deben ir en PNG o JPG)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[a4paper, 12pt]{book}
\usepackage[T1]{fontenc}

\usepackage[a4paper, left=2.5cm, right=2.5cm, top=3cm, bottom=3cm]{geometry}
\usepackage{times}
\usepackage[latin1]{inputenc}
\usepackage[spanish]{babel} % Comenta esta l\'inea si tu memoria es en ingl\'es
\usepackage{url}
\usepackage{nicefrac}
%\usepackage[dvipdfm]{graphicx}
\usepackage{graphicx}
\usepackage{float}  %% H para posicionar figuras
\usepackage[nottoc, notlot, notlof, notindex]{tocbibind} %% Opciones de \'indice
\usepackage{latexsym}  %% Logo LaTeX
\usepackage{eurosym}
\usepackage{subfig}


% Default fixed font does not support bold face
\DeclareFixedFont{\ttb}{T1}{txtt}{bx}{n}{12} % for bold
\DeclareFixedFont{\ttm}{T1}{txtt}{m}{n}{12}  % for normal

% Custom colors
\usepackage{color}
\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{deepred}{rgb}{0.6,0,0}
\definecolor{deepgreen}{rgb}{0,0.5,0}
\definecolor{gray97}{gray}{.97}
\definecolor{gray75}{gray}{.75}
\definecolor{gray45}{gray}{.45}

\usepackage{listings}

% Python style for highlighting
\newcommand\pythonstyle{\lstset{
language=Python,
basicstyle=\scriptsize,
otherkeywords={self},             % Add keywords here
keywordstyle=\scriptsize\color{deepblue},
emph={MyClass,__init__},          % Custom highlighting
emphstyle=\scriptsize\color{deepred},    % Custom highlighting style
stringstyle=\color{deepgreen},
frame=Ltb,                         % Any extra options here
showstringspaces=false            % 
framerule=0pt,
aboveskip=0.5cm,
framextopmargin=3pt,
framexbottommargin=3pt,
framexleftmargin=0.4cm,
framesep=0pt,
rulesep=.4pt,
backgroundcolor=\color{gray97},
rulesepcolor=\color{black},
commentstyle=\color{gray45},
numbers=left,
numbersep=15pt,
numberstyle=\scriptsize,
numberfirstline = false,
breaklines=true,
}}


% Python environment
\lstnewenvironment{python}[1][]
{
\pythonstyle
\lstset{#1}
}
{}

% Python for external files
\newcommand\pythonexternal[2][]{{
\pythonstyle
\lstinputlisting[#1]{#2}}}

% Python for inline
\newcommand\pythoninline[1]{{\pythonstyle\lstinline!#1!}}




\title{Rob\'otica aérea con aviones}
\author{José Antonio Fernández Casillas}

\renewcommand{\baselinestretch}{1.5}  %% Interlineado

\begin{document}

\renewcommand{\refname}{Bibliograf\'ia}  %% Renombrando
\renewcommand{\appendixname}{Ap\'endice}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% PORTADA

\begin{titlepage}
\begin{center}
\begin{tabular}[c]{c c}
%\includegraphics[bb=0 0 194 352, scale=0.25]{logo} &
\includegraphics[scale=0.25]{img/logo_vect.png} &
\begin{tabular}[b]{l}
\Huge
\textsf{UNIVERSIDAD} \\
\Huge
\textsf{REY JUAN CARLOS} \\
\end{tabular}
\\
\end{tabular}

\vspace{3cm}

\Large
INGENIERÍA TÉCNICA INFORMÁTICA EN SISTEMAS

\vspace{0.4cm}

\large
Curso Acad\'emico 2011/2017

\vspace{0.8cm}

Proyecto Fin de Carrera

\vspace{2.5cm}

\LARGE
ROB\'oTICA AÉREA CON AVIONES

\vspace{4cm}

\large
Autor : José Antonio Fernández Casillas \\
Tutor : José María Cañas Plaza
\end{center}
\end{titlepage}

\newpage
\mbox{}
\thispagestyle{empty} % para que no se numere esta pagina


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Para firmar
\clearpage
\pagenumbering{gobble}
\chapter*{}

\vspace{-4cm}
\begin{center}
\LARGE
\textbf{Proyecto Fin de Carrera}

\vspace{1cm}
\large
Rob\'otica aérea con aviones

\vspace{1cm}
\large
\textbf{Autor :} José Antonio Fernández Casillas
\textbf{Tutor :} José María Cañas Plaza

\end{center}

\vspace{1cm}
La defensa del presente Proyecto Fin de Carrera se realiz\'o el d\'ia \qquad$\;\,$ de \qquad\qquad\qquad\qquad \newline de 20XX, siendo calificada por el siguiente tribunal:


\vspace{0.5cm}
\textbf{Presidente:}

\vspace{1.2cm}
\textbf{Secretario:}

\vspace{1.2cm}
\textbf{Vocal:}


\vspace{1.2cm}
y habiendo obtenido la siguiente calificaci\'on:

\vspace{1cm}
\textbf{Calificaci\'on:}


\vspace{1cm}
\begin{flushright}
Fuenlabrada, a \qquad$\;\,$ de \qquad\qquad\qquad\qquad de 20XX
\end{flushright}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Dedicatoria

\chapter*{}
\pagenumbering{Roman} % para comenzar la numeracion de paginas en numeros romanos
\begin{flushright}
\textit{Dedicado a \\
mi familia / mi abuelo / mi abuela}
\end{flushright}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Agradecimientos

\chapter*{Agradecimientos}
%\addcontentsline{toc}{chapter}{Agradecimientos} % si queremos que aparezca en el \'indice
\markboth{AGRADECIMIENTOS}{AGRADECIMIENTOS} % encabezado 

Aqu\'i vienen los agradecimientos\ldots Aunque est\'a bien acordarse de la pareja,
no hay que olvidarse de dar las gracias a tu madre, que aunque a veces no lo 
parezca disfrutar\'a tanto de tus logros como t\'u\ldots Adem\'as, la pareja quiz\'as
no sea para siempre, pero tu madre s\'i.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Resumen

\chapter*{Resumen}
%\addcontentsline{toc}{chapter}{Resumen} % si queremos que aparezca en el \'indice
\markboth{RESUMEN}{RESUMEN} % encabezado

Aqu\'i viene un resumen del proyecto. Ha de constar de tres o cuatro p\'arrafos,
donde se presente de manera clara y concisa de qu\'e va el proyecto. Han
de quedar respondidas las siguientes preguntas:

\begin{itemize}
  \item ¿De qu\'e va este proyecto? ¿Cu\'al es su objetivo principal?
  \item ¿C\'omo se ha realizado? ¿Qu\'e tecnolog\'ias est\'an involucradas?
  \item ¿En qu\'e contexto se ha realizado el proyecto? ¿Es un proyecto
dentro de un marco general?
\end{itemize}

Lo mejor es escribir el resumen al final.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Resumen en ingl\'es

\chapter*{Summary}
%\addcontentsline{toc}{chapter}{Summary} % si queremos que aparezca en el \'indice
\markboth{SUMMARY}{SUMMARY} % encabezado

Here comes a translation of the ``Resumen'' into English. Please, double check
it for correct grammar and spelling. As it is the translation of the ``Resumen'',
which is supposed to be written at the end, this as well should be filled out
just before submitting.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \'iNDICES %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Las buenas noticias es que los \'indices se generan autom\'aticamente.
% Lo \'unico que tienes que hacer es elegir cu\'ales quieren que se generen,
% y comentar/descomentar esa instrucci\'on de LaTeX.

%%%% \'indice de contenidos
\tableofcontents 
%%%% \'indice de figuras
\cleardoublepage
%\addcontentsline{toc}{chapter}{Lista de figuras} % para que aparezca en el indice de contenidos
\listoffigures % indice de figuras
%%%% \'indice de tablas
%\cleardoublepage
%\addcontentsline{toc}{chapter}{Lista de tablas} % para que aparezca en el indice de contenidos
%\listoftables % indice de tablas


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% INTRODUCCI\'oN %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Introducci\'on}
\label{sec:intro} % etiqueta para poder referenciar luego en el texto con ~\ref{sec:intro}
\pagenumbering{arabic} % para empezar la numeraci\'on de p\'agina con n\'umeros

Los UAV o Drones se han popularizado en los \'ultimos años hasta es punto de formar parte de nuestro d\'ia a d\'ia con aplicaciones en muchos ambitos de nuestra vida. 

Si bien se est\'an utilizando ya de forma habitual en sectores como el cine o la ingenier\'ia civil, a\'un se est\'an explorando muchas de las posibles utilidades que estos robots pueden llegar a ofrecer.

El objetivo de este trabajo final es poner en valor y asentar el uso de un tipo de UAV que no est\'a hoy muy representado en el \'ambito civil y que aventaja en varios aspectos al más popularizado quadrac\'optero, se trata del avi\'on.

\section{Rob\'otica A\'erea}
\label{sec:robotica_aerea}

Los or\'igenes de la rob\'otica aerea tienen origen militar y su avance ha estado intr\'insecamente ligado a este \'ambito durante todo el siglo XX.

Se consideran el origen de los aviones no tripulados los experimentos llevados a cabo a principios del siglo XX durante la 1ª guerra mundial como el 'Aerial Target' desarrollado por el capit\'an A. H. Lowpara para su uso como blanco a\'ereo. Si bien eran veh\'iculos no tripulados (Unmaned Aereal Vehicles) no eran aut\'onomos y eran manejados desde tierra a trav\'es de una radio. 
No es hasta el final del siglo XX cuando bajo el escenario de la guerra de Vietnam y ante la creciente perdida de vidas de los pilotos estos veh\'iculos vuelvan de nuevo a ser objeto de desarrollo y se conviertan en veh\'iculos aut\'onomos.

Desde ese momento y hasta nuestros d\'ias se utilizan de forma habitual en el \'ambito militar en misiones de reconocimiento, bombardeos o apoyo sin arriesgar vidas humanas.

A los largo de los primeros años de este siglo debido al abaratamiento de los componentes electr\'onicos y a su minituarizaci\'on y potencia, la rob\'otica a\'erea se ha 'desmilitarizado' y esta experimentado un enorme crecimiento en el \'ambito de las aplicaciones civiles.

Hoy en d\'ia es com\'un encontrar en cualquier jugueter\'ia quadrac\'opetros radio-pilotados por poco menos de 30 euros y en tiendas especializadas podemos encontrarlos ya con el hardware y software integrados que les permiten seguir una serie de puntos de control y comportarse de forma aut\'onoma por poco más de 200 \euro.

En la actualidad el uso de AUV o drones se ha popularizado tanto que es una de las industrias en las que más ha crecido su inversi\'on, y es que seg\'un la empresa analista especializada en dones Droneii con sede en Hamburgo en un estudio sobre la inversi\'on en el sector\footnote{\url{http://www.droneii.com/drone-investment-trends-2016}} en europa se invirti\'o en en proyectos dom\'esticos en 2016 cerca de 65 millones de d\'olares increment\'andose esta cifra hasta los 314 millones si atendemos al mercado norteamericano.

Estas datos se asientan en un mercado cada vez más extendido y con una gran proyecci\'on de crecimiento,la publicaci\'on BI Intelligence\footnote{\url{http://www.businessinsider.com/the-drones-report-research-use-cases-regulations-and-issues-2016-4}} espera que las ventas de drones alcancen los 12.000 millones en 2021.
La venta de drones es s\'olo una de las piezas de éste negocio incipiente, empresas como DJI, Xiaomy o 3DR estan en la punta de lanza de la  innovaci\'on desarrollo de éstos, pero es tán solo la punta del iceberg. Esta industria está potenciando otras como la de las videocámaras deportivas GoPRO e incluso estan surgiendo nuevos puestos de trabajo como el de operador de drones.
Las grandes empresas tecnol\'ogicas ven el potencial econ\'omico que pueden aportar a sus balances y se está produciendo una pugna por adquirir las principales empresas esecializadas en drones, Verizon compr\'o en febrero Skyward, facebook compr\'o Acenta y google 

La enorme aceptaci\'on y expansi\'on de los drones se ha producido de un modo tan explosivo, que en ciertos aspectos de la sociedad no se ha avanzado lo suficiente como para que su utilizaci\'on se haga de forma segura.

\begin{itemize}
\item Problemas de seguridad. Los drones y en especial los drones de gran envergadura más allá de su uso profesional o lúdico pueden ser muy peligrosos. Sus palas giran a mas de 1000RPM y pueden producir cortes o amputaciones o producir daños personales y/o materiales en el caso de una pérdida de control del mismo o una caída. Esto se hizo patente cuando durante la filmaci\'on de un concierto del cantante Enrique Iglesias en Tijuana (México) éste agarr\'o el drone que le grababa de forma espontánea y ésto le produjo severos cortes en su mano derecha que hizo que sangrase profusamente.

También pueden utilizarse con fines terroristas como se sospech\'o en Francia cuando se detectaron en octubre de 2014 volando en las proximidades de varias centrales nucleares. Además, en la noche del 19 al 20 de enero de 2015 otro 'dron' sobrevol\'o el Palacio del Elíseo, donde tiene su residencia el presidente de la república Francesa, Françoise Hollande. Y a ellos hay que sumar los 19 'drones' que han sido avistados sobrevolando 17 centrales nucleares francesas de octubre a febrero de 2015.
De hecho en el ámbito militar los drones son parte importante del despliegue militar del IS (Estado islamico) quien con vídeo e infografías como la siguiente se jactan de sus "logros' con ellas en las redes sociales. Su bajo coste y su versatilidad producen que proliferen muchos drones construidos por sus militantes para la guerra.


\begin{figure}[h]
\centering
  \subfloat[Infograf\'ia publicada por el IS en twitter]{
   \label{f:infografia_is}
    \includegraphics[width=0.4\textwidth]{img/IS_drones.jpg}}
  \subfloat[Dron casero del IS]{
   \label{f:diy_is_drone}
    \includegraphics[width=0.475\textwidth]{img/IS_drones_DIY.jpg}}
 \label{f:is}
\end{figure}
Algunas empresas del sector se han hecho eco de estos ataques y han deshabilitado sus drones en zonas de conflicto para evitar que se utilicen como armas de guerra como es el caso de la empresa china DJI líder en el sector.\footnote{\url{http://clipset.20minutos.es/dji-bloquea-drones-guerra-irak-siria/}}

A estos problemas de seguridad hay que unir el problema del Hacking, muchos de los más extendidos drones comerciales no tienen protecci\'on alguna contra el ataque de un ciberdelincuente. Por poner un ejemplo el modo en el que el Parrot AR-Drone se empareja con el m\'ovil es una conexi\'on plana sin contraseña, haciendo posible conectarse a el por un tercero con unas pocas líneas de c\'odigo.
\begin{itemize}
\item Guía sencilla de hacking del AR-Drone 2.0 - http://www.xdrones.es/guia-para-hackear-el-ar-drone-2-0/
\item C\'omo atacar el AR-Drone 2.0 con nodecopter - http://www.nodecopter.com/hack
\item Suit para hackear drones a través de WIFI - https://github.com/samyk/skyjack
\end{itemize}
Si bien es relativamente simple su hackeo el daño que pueda producirse con ellos es mas bien leve o muy moderado, pero existen técnicas como el GPS Spoofing que pueden "secuestrar'cualquier drone que se guíe por GPS como ocurri\'o en Irán en 2011 d\'onde hackers iraníes se hicieron con el control de un drone militar americano Lockheed Martin RQ-170 Sentinel\footnote{\url{https://en.wikipedia.org/wiki/Iran\%E2\%80\%93U.S._RQ-170_incident}} mediante ésta técnica que engaña a la antena GPS del UAV haciéndole pensar que se encuentra en otro lugar. Si bien para éste ataque se necesit\'o un hardware caro que haría el ataque prohibitivo, hoy es posible realizarlo por unos pocos cientos de euros con hackrf o braderf como se demostr\'o por la compañía china Qihoo 360 en las conferencias de Haking DEFCON de 2015.\footnote{\url{http://www.rtl-sdr.com/spoofing-gps-locations-with-low-cost-tx-sdrs/}}

\item Problemas regulatorios. Otro problema importante que apenas se está empezando a abordar es el regulatorio. Con el fin de minimizar el riesgo para las personas se está llevando a cabo una regulaci\'on del sector en todo el mundo. En España por ejemplo hasta abril de 2014, volar un dron para uso civil estaba absolutamente prohibido. La no regulaci\'on no indicaba que se pudiese volar, indicaba más bien todo lo contrario. Otro tema es el desconocimiento total por parte de las fuerzas del orden del Estado, donde una persona volase un drone y nadie le dijese nada.
En éste marco regulatorio no se puede por ejemplo, volar un dron en núcleos urbanos, s\'olo debe hacerse en zonas previstas a tal efecto. Tampoco es posible volar un dron de más de 2Kg más allá de donde puedas verlo (500m), y es que antes era muy usual ponerle una cámara y volar varios kil\'ometros con él.

Para hacernos una idea clara del marco regulatorio actual para su uso no profesional basta con fijarnos en la siguiente infografía publicada por la agencia EFE.
\begin{figure}[H]
  \centering
  \includegraphics[scale=0.50]{img/infografia_legislacion_drones.jpg}
  \caption{Infografía de la Agencia EFE con la regulaci\'on}
  \label{fig:infografia_efe}
\end{figure}

Para poder utilizar los drones con fines profesionales la ley es aún más restrictiva la Agencia Española de Seguridad Aérea AESA exige el registro de las aeronaves civiles pilotadas por control remoto cuya masa máxima al despegue exceda de 25 kg, que deberán estar inscritas en el Registro de matrícula de aeronaves y disponer de certificado de aeronavegabilidad.
Para drones de menor peso, el piloto deberá presentar ante la Agencia Estatal de Seguridad Aérea una comunicaci\'on previa y declaraci\'on responsable) con una antelaci\'on mínima de cinco días al día del inicio de la operaci\'on y éste ha de estar habilitado como operdor de drones.

La ley completa se puede consultar el BOE\footnote{\url{ http://www.seguridadaerea.gob.es/media/4243006/rdl_8_2014_4julio.pdf}}

\end{itemize}

Con su uso ya ampliamente extendido en sectores como el cine, la televisi\'on, fotograf\'ia, agropecuario, forestal, ingenier\'ia civil y presencia en sectores como el de salvamento o seguridad y protecci\'on el nicho de mercado de los UAV esta lejos de su cima y se investigan dia a dia nuevos usos en sectores como el de la log\'istica o las telecomunicaciones como veremos mas adelante suponiendo un reto constante para investigadores, desarrolladores, ingenieros, inversores y entidades regulatorias.



\section{Tipos de Aeronaves}
\label{sec:tipos_aeronaves}


Las aeronaves son la base sobre las que se asienta la inteligencia que permite que nuestro robot vuele de ah\'i que convenga dedicar unas l\'ineas a entender la base de las mismás y en particular las que son objeto de estudio y desarrollo en este PFC los llamados aerodinos.

Los aerodinos son aquellas aeronaves que vuelan a pesar de pesar más que el aire, son capaces de generar sustentaci\'on por sus propios medios a diferencia de los aerostatos como por ejemplo los globos aerost\'aticos.

Existen principalmente 2 tipos de aerodinos si atendemos al modo en que generan su sustentaci\'on con sus alas, de ala fija y las de ala rotatoria.

Dentro de la tipificaci\'on de ala fija tenemos aquellas aerodinos que tienes sus alas fijas al fuselaje, y que comunmente conocemos como aviones, seg\'un la OACI, un avi\'on es un «Aerodino propulsado por motor, que debe su sustentaci\'on en vuelo principalmente a reacciones aerodin\'amicas ejercidas sobre superficies que permanecen fijas en determinadas condiciones de vuelo»
Algunos ejemplos de aerodinos de ala fija son los aeroplanos, planeadores/veleros, aladeltas, parapentes, paramotores y ultraligeros.

Este tipo de aerodinos tienen como principal ventaja que la carga de aire que necesitan en sus alas puede ser producida de muchas formás distinta (los veleros no tienen ning\'un tipo de propulsi\'on). Esta carga es variable en funci\'on de la superficie alar del mismo y permite por tanto cargas más grandes que si instal\'asemos el mismo propulsor en un ala rotatoria.
Pongamos como ejemplo el A380 de Airbus, es el avi\'on de pasajeros más grande del mundo y cuenta con 4 motores que producen un empuje de entre 70.000 y 80.000lbs, unas 32-36 toneladas de empuje cada uno generando por  tanto entre los 4 a m\'aximo rendimiento y optimás condiciones alrededor de 144 toneladas de empuje. Este avi\'on tiene un peso m\'aximo al despegue\footnote{Peso m\'aximo que es capaz de soportar un avi\'on en su maniobra de despegue}\ de entre 560 y 590 toneladas. Tenemos por tanto que necesitamos en este caso \nicefrac{1}{4} del peso total en empuje para despegar este avi\'on.
Si hici\'esemos este mismo ejercicio con un aerodino de ala rotatoria como el Boing AH-64 o Apache con un peso m\'aximo al despegue de 9,5 toneladas necesitar\'iamos que la combinaci\'on que realizan empuje y palas superase esos 9,5 toneladas para siguiera levantar del suelo.
Este tipo de aerodinos son por tanto más eficientes, r\'apidos, con mayor carga de pago, mayor alcance debido a su menor consumo y más estables.

Dentro de la tipificaci\'on de ala rotatoria tenemos aquellas aerodinos que producen su sustentaci\'on con el movimiento (rotaci\'on) de sus alas. En este tipo de aerodinos las alas, tambi\'en llamadas 'palas' en este tipo de aerodinos, giran en torno a un eje produciendo con este giro la sustentaci\'on necesaria para despegar del suelo.
Algunos ejemplos de este tipo de aerodinos son los helic\'opteros, autogiros, convertibles o los ampliamente conocidos en robotica aerea los quadrac\'opteros.
Este tipo de aerodino tiene como principal ventaja frente a los ala fija en su versatilidad a la hora de realizar las maniobras de despegue y aterrizaje que pueden realizarse de forma vertical (VTOL\footnote{Vertical take off and landing }) adem\'as de la capacidad de realizar vuelo estacionario\footnote{Mantenerse est\'aticamente en un punto elevado} que le hacen imprescindible en escenarios poco accesibles o donde nos es posible aterrizar como el rescate mar\'itimo.


\section{Aplicaciones}
\label{sec:aplicaciones}

La rob\'otica a\'erea ha experimentado un crecimiento exponencial en los \'ultimos años, se ha popularizado su uso y se ha extendido la comercializaci\'on de drones.

El sector donde m\'as r\'apida acogida ha tenido la rob\'otica a\'erea ha sido el sector audiovisual, se usa de forma habitual en cine, grabaci\'on de espect\'aculos en directo televisi\'on y fotograf\'ia. El porqu\'e de tal acogida se basa principalmente en 2 factores, los costes y la viabilidad t\'ecnica. 
Los costes de realizar una toma a\'erea en una producci\'on antes pasaban por el alquiler de un helic\'optero, dependiendo de la toma, as\'i como del material y la contrataci\'on de los medios humanos a bordo para realizarlas pod\'ia ascender a entre 4000 y 6000 euros la hora. Hoy en d\'ia basta con un pequeño dronde entre 400 y 1800 euros\footnote{Precios aproximados extra\'idos de la empresa especializada World Aviation Helicopters \url{https://www.worldaviation.es/es/servicio-drones.aspx}} por jornada e incluir\'ian en el tramo más elevado piloto y operador de c\'amara.
Como se puede constatar f\'acilmente el ahorro incurrido no es para nada desdeñable y ofrece a pequeñas productoras acceder a \'este tipo de grabaciones que de otro modo ser\'ian privativas para \'estas.
Aunque aspecto econ\'omico es especialmente importante para decantarse por el uso de este tipo de medios, existen en el mundo audiovisual trabajos que no hubiesen sido posibles hasta este momento gracias a los drones. Grabaciones en las que el riesgo humano y material que habr\'ia que asumir es tan alto que t\'an solo de \'este modo, debemos por tanto a los drones fotograf\'ias como \'esta que si bien nos se tom\'o como parte de ningún proyecto cinematográfico nos hace una idea de lo que la rob\'otica aérea puede ofrecernos.
\begin{figure}[H]
  \centering
  \includegraphics[scale=0.30]{img/drone_volcan.jpg}
  \caption{Dron grabando en el interior de un crater}
  \label{fig:drone_volcan}
\end{figure}
Otro sector que ha adaptado rápidamente el uso de éstas pequeñas aeronaves es el agropecuario donde se utiliza para medir la condiciones del terreno, con el fin de recoger informaci\'on sobre la hidrataci\'on, la temperatura o el ritmo de crecimiento de los cultivos. Controlan el riego e incluso esparcen los pesticidas de manera eficiente siendo un arma eficaz contra las plagas, se utilizan incluso como espantapájaros.
La aplicaci\'on de drones en este sector se remonta a 1983 cuando el Ministerio de Agricultura de Jap\'on preocupado por el envejecimiento de su poblaci\'on rural encarg\'o a Yamaha el desarrollo de una aeronave no tripulada capaz de realizar varias tareas de las anteriormente descritas a fin de atraer más gente al medio rural. En 1990 se entregaron las primeras unidades del Yamaha RMAX y actualmente el 40\% de los arrozales japoneses cuentan con un dron sobrevolándolos.

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.30]{img/Yamaha_crop_Sprayer_Drone_RMAX.jpg}
  \caption{Dron Yamaha RMAX fumigando}
  \label{fig:drone_yamaha}
\end{figure}


Son utilizados también por los servicios de rescate tras una catástrofe para evaluar los daños experimentados y ayudas a encontrar supervivientes entre los escombros. Algunos son capaces de enviar a los supervivientes paquetes de supervivencia con salvavidas, alimentos o agua mientras esperan su rescate\footnote{\url{http://www.elmundo.es/economia/2015/09/15/55f8239546163fc6598b45c3.html}}

E incluso se han empezado a utilizar por el Ministerio de Hacienda de España con fines recaudatorios, sobrevuelan las viviendas o fincas localizando edificaciones no registradas por el catastro con el fin de regularizar su situaci\'on.

El uso de drones es especialmente importante en el ámbito científico para por ejemplo tomar medidas de temperatura y CO2 en zonas peligrosas\footnote{\url{http://www.igepn.edu.ec/servicios/noticias/1395-medidas-de-temperatura-y-co2-de-las-fumarolas-muestreo-y-fotografias-con-drone}}, estudiar las nubes volcánicas\footnote{\url{https://www.nasa.gov/topics/earth/earthmonth/volcanic-plume-uavs.html}} o volar dentro de una grieta en un glaciar\footnote{\url{http://tn.com.ar/tecno/recomendados/increible-un-drone-volo-dentro-de-un-glaciar_648661}}. 

El futuro del uso de los drones se está escribiendo en este mismo momento y es que poco a poco se investigan con nuevos usos o c\'omo mejorar los ya actuales. 

Uno de los usos más prometedores que esta siendo investigado es el uso de drones para la logística y paquetería, Amazon estudi\'o en 2105 la viabilidad de utilizar drones para el reparto, especialmente en zonas de difícil acceso o bien alejadas de las zonas habituales de reparto. A finales de dicho año realiz\'o pruebas de entregas en el reino unido y desarrollo un prototipo de alrededor de 25Kg de peso. El objetivo de Amazon, entregas de menos de 3Kg en 30 minutos y una toma de contacto en la entrega de paquetes en zonas pobladas.
Esto a dado pie a las principales empresas de logística y paquetería a realizar sus propios desarrollos y constuir sus propios prototipos. 
DHL ha realizado sendas pruebas con drones de cerca de 5 Kg para la entrega de paquetes de hasta 1,2 Kg.
La empresa francesa GeoPost se ha con la empresa Atechsys, especializada en el desarrollo de sistemás aut\'onomos para aeronaves no tripuladas, que ha dado como resultado un dron que cuenta con seis rotores eléctricos y estructura de fibra de carbono, con capacidad para llevar paquetes de un peso aproximado de hasta 2 kilos.
UPS ha realizado un experimento en tampa con un octoc\'optero que despegaría desde el techo de la furgoneta de reparto para entregar los paquetes en zonas rurales y ahorrar en kilometraje el dron tendía una carga de pago de unos 4,5Kg.

Otro de los estudios que más llama la atenci\'on es el de Google y Facebook que compiten en llevar internet a zonas aisladas a través de una re de drones y satélites.
Facebook present\'o en su F8 en Marzo de 2015 su prototipo de dron a tal efecto, Aquila, fruto de la adquisici\'on de la empresa especializa en rob\'otica aérea Acenta. Este proyecto se enmarca dentro del plan internet.org y liderado Connectivity Lab\footnote{Un equipo formado por 50 expertos en aeronáutica y ciencia espacial} que pretende ofrecer internet con un coste reducido a todo aquel que no lo tenga.
En 2014 Google por su parte compr\'o Titan Aeroespace para crear una flota de drones propulsados por energía solar, capaces de volar más de una semana mientras tomaban fotos de la superficie y proveían de acceso a Internet a lugares remotos y proveer nueva informaci\'on para sus mapas. Éste desarrollo sin embargo se ha abandonado en enero de éste año en pro de la utlizacion de globos aerostáticos para tal prop\'osito.
 
\section{Rob\'otica a\'erea en el laboratorio de Rob\'otica de la URJC}
\label{sec:lab_robotica}

Dentro del laboratorio de rob\'otica de la Universidad Rey Juan Carlos cabe destacar los trabajos realizados para profundizar investigar y experimentar con ellos.

Trabajos como el de Alberto Mart\'inez Florido permiti\'o controlar un AR-Drone real desde una aplicaci\'on cliente, desarrollando para ello un driver para el dron, ardrone\_server y una aplicacci\'on cliente UAV Viewer.
El driver ardrone\_server es capaz de conectar con el AR-DRONE a través de comandos AT tanto para obtener los datos de todos sus sensores como para controlarlo y expone todo ello en interfaces JdeRobot para su interconexi\'on con todo el software disponible en el framework.
El AR-Drone es un quadrac\'optero que en su versi\'on actual cuenta con aceler\'ometros, gir\'oscopos y magnet\'ometros en 3 ejes que determinan junto con su bar\'ometro y un sensor de ultrasonidos la actitud del mismo, dispone además de 2 cámaras, una ventral y otra frontal y algunos modelos traen sensor GPS.
Alberto desarroll\'o también el software de control UAV Viewer, esta aplicaci\'on cliente es capaz de controlar con cualquier drone y mostrar de forma visual su actitud, lo que captan sus cámaras.

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.30]{img/uavviewer.png}
  \caption{Ventanas de UAV Viewer}
  \label{fig:uavviewer}
\end{figure}

Daniel Yague desarroll\'o un driver para poder simular el comportamiento del AD-Dronde en el simulador Gazebo, de referencia en el departamento de rob\'otica de la universidad y contenido dentro de la suite JdeRobot. Con este desarrollo se hizo posible desarrollar, probar anticipar los problemas que puedan surgir en el vuelo del dron antes siquiera de volarlo, de esta forma es posible el desarrollo de aplicaciones de navegaci\'on complejas sin disponer de el, sin arriesgarlo e independientemente de factores externos como la climatología.
Para mostrar las posibilidades de desarrollo que se abrían desarroll\'o varias aplicaciones en el ar-drone simulado como un gato-rat\'on donde un dron teleoperado trataba de huir de otro que le seguía o una aplicaci\'on donde el dron seguía una carretera.

Jorge Cano construy\'o propio su dron utilizando como base un quadrac\'optero con un Intel Compute Stick (ICS) STCK1A8LFC como ordenador de abordo y una placa Pixhawnk como placa estabilizadora/piloto automático. Esta placa utiliza como protocolo de comunicaci\'on MAVLink\footnote{Micro Air Vehicle Link \url{https://en.wikipedia.org/wiki/MAVLink}} y dispone de aceler\'ometros, gir\'oscopos y magnet\'ometros para determinar la actitud.
Además de la construcci\'on del drone Jorge desarroll\'o el driver MAVLinkServer donde apoyándose en MAVProxy adapt\'o los comandos MAVLink a interfaces JdeRobot permitiendo acceder a la actitud y controlar el drone con comandos tipo GotoXY enviados a través del interfaz Pose3D\footnote{Ver capítulo 3 Arquitectura utilizada}

\begin{figure}[h]
\centering
  \subfloat[Intel]{
   \label{f:Ordenador de abordo}
    \includegraphics[width=0.3\textwidth]{img/Compuandcaminstall.JPG}}
  \subfloat[camaras]{
   \label{f:Cámaras de abordo}
    \includegraphics[width=0.535\textwidth]{img/FPVcamara.jpg}}
 \label{f:drone_cano}
\end{figure}

En la actualidad se estan desarrollando nuevos trabajos sobre este tipo de placas estabilizadoras que tiene como software base ArduCopter/Ardupilot o son compatibles.

Diego Jimenez trabaja en controlar un Solo Drone de la empresa 3DR\footnote{Empresa norteamericana con sede en California especializada en rob\'otica a\'erea. Se sit\'ua en 2017 como la 3ª empresa del sector} mediante el interfaz de velocidades CMDVel\footnote{Ver capítulo 3 Arquitectura utilizada}, este quadrac\'otero tiene como placa de control una Pixhawnk como la utilizada por Jorge Vela en el dron que se construy\'o y utiliza también comamdos MAVLink.

Jorge Vela se encuentra desarrollando como realizar la maniobra de aterrizaje de forma autom\'atica al localizar un patr\'on o baliza localizado visi\'on, como drone estan utilizando un Solo Drone con una Intel Stick como ordenador de abordo.

\chapter{Objetivos}
\label{sec:objetivos}


\section{Problema a abordar}
\label{problema}
Los objetivos de este proyecto final de carrera es dar un soporte en la plataforma software JdeRobot para drones de ala fija que utilicen como interfaz de comunicaci\'on MAVLink. Para abordar el problema lo hemos divido en 5 grandes Milestones:
\begin{enumerate}
\item Preparaci\'on del hardware necesario para abordar el problema con un avi\'on real.
\item Desarrollo de un driver que acceda a los sensores y actuadores de drones de ala fija que utlicen MAVLink y dar soporte a la actuaci\'on de misiones que hasta ahora no soportaba JdeRobot el driver se llamara APM Server siglas de Ardupilot Mega Server.
\item Desarrollo de una aplicaci\'on GCS Ground Control Station que permita al operador introducir misiones y seguir el cumplimiento de las mismas a través de el. Permitiendo el acceso a toda la actitud y a las cámaras de abordo. Se llamará UAV Commander.
\item Experimentos en simulaci\'on. Conectaremos nuestro driver APM Server al simulador SITL y el UAV Commander al APM Server para poder simular el seguimiento de misiones.
\item Experimentos en el avi\'on real. Montaremos la avi\'onica en el avi\'on real y lo llevaremos al campo de vuelo para validar su comportamiento.
\end{enumerate}

\section{Requisitos}
\label{requisitos}

Para abordar con éxito los milestones expuestos anteriormente debemos cubrir los siguientes requisitos:
\begin{enumerate}
	\item Preparaci\'on del hardware necesario.
	\begin{enumerate}
		\item Compra del hardware necesario:
		\begin{itemize}
			\item Raspberry Pi, se empez\'o por la Raspberry 2 y se ha adquirido posteriormente la 3.
			\item Cámara Picam.
			\item Ardupilot Mega junto con GPS.
			\item Avi\'on de radiocontrol Bix3.
			\item Kit de motorizaci\'on más potente.
		\end{itemize}
		\item Instalaci\'on de Raspbian y JdeRobot en Raspberry Pi.
		\item Pruebas de vídeo en Raspberry Pi con cameraserver.
	\end{enumerate}
	\item APM Server
	\begin{enumerate}
		\item Dar acceso a los sensores del APM y servir en forma de Pose3D y NavData:
		\begin{enumerate}
			\item Conectar con el APM
			\item Leer los mensajes que envían sus sensores.
			\item Implementar los interfaces Pose3D y NavData con esta informaci\'on.
			\item Servir a través de Ice todos los interfaces.
		\end{enumerate}
		\item Dar acceso a instrucciones de actuaci\'on a través del interfaz mission.
		\begin{enumerate}
			\item Recibir a través de Ice un objeto de misi\'on.
			\item Construir los comandos MAVLink necesarios para que el APM sepa interpretar y realizar la misi\'on.
			\item Recibir los comandos de despegue y aterrizaje a través del interfaz Extra.
			\item Construir los comandos MAVLink necesarios para que el APM sepa interpretarlos y añadirlos a la misi\'on.
		\end{enumerate}
	\end{enumerate}
	\item UAV Commander
	\begin{enumerate}	
		\item Recibir toda la informaci\'on sensorial a partir de los interfaces Ice Pose3D y NavData.
		\item Funcionalidad de creaci\'on de misiones:
		\begin{enumerate}
			\item Recuperar mapa georeferenciado de un servicio WMS.
			\item Capacidad de actuar sobre él para añadir puntos de misi\'on.
			\item Añadir botones de despegue y aterrizaje que interactúen con el mapa.
			\item Borrado de misi\'on actual.
			\item Envío de misi\'on al APM.
		\end{enumerate}
		\item Funcionalidad de seguimiento de misiones:
		\begin{enumerate}
			\item Pintar estela del avi\'on en el mapa.
			\item Recuperar nuevo mapa con mayor zoom si se prevee la salida del actual mapa.
		\end{enumerate}
		\item Acceso a la informaci\'on de actitud de forma visual.
		\item Acceso a las cámaras de abordo.
	\end{enumerate}	
	\item Experimentos en simulaci\'on.
	\begin{enumerate}
		\item Montaje de máquina virtual para el simulador
		\item Instalaci\'on de SITL.
		\item Conectar APM server a SITL.
		\item Ejecuci\'on de plan de pruebas simuladas:
		\begin{enumerate}
			\item Prueba de integraci\'on de todo el software.
			\item Prueba envío de misi\'on con avi\'on en vuelo.
			\item Prueba de envío de misi\'on con despegue y varios waypoints.
			\item Prueba de envío de misi\'on con despegue y aterrizaje.
			\item Prueba de autozoom forzando la salida del avi\'on del mapa.
		\end{enumerate}
	\end{enumerate}
	\item Experimentos en el avi\'on real.
	\begin{enumerate}
		\item Pruebas de envío recepci\'on del sistema de radiofrecuencias.
		\item Pruebas de conexi\'on con APM Server y UAV Commander.
		\item Ejecuci\'on de plan de pruebas:
		\begin{enumerate}
			\item Pruebas de seguimiento del avi\'on a través del UAV Commander.	
			\item Prueba de envío de misi\'on desde el avi\'on en vuelo.
		\end{enumerate}
\end{enumerate}
\end{enumerate}

Cómo requisitos no funcionales debemos:
\begin{enumerate}
\item Ser multiplataforma.
\item Utilizar únicamente librerías de software libre.
\item Ser 100\% compatibles con los actuales interfaces JdeRobot.
\end{enumerate}

\section{Metodología y plan de trabajo}
\label{metodología}

Este proyecto se ha abordado en con 2 metodologías de trabajo distintas que combinadas, la primera metodología de desarroll\'o aplicada es el desarrollo en espiral que se ha utilizado como metodología principal, y la segunda que se ha aplicado la metodología ágil Kanban, para un control de tareas y subtareas más eficiente.

\begin{figure}[h]
\centering
  \subfloat[Representaci\'on gráfica del desarrollo en espiral.]{
   \label{f:espiral}
    \includegraphics[width=0.4\textwidth]{img/359px-ModeloEspiral.png}}
  \subfloat[Representación de una pizarra kanban]{
   \label{f:kanban}
    \includegraphics[width=0.52\textwidth]{img/kanban.png}}
\end{figure}


El modelo de desarrollo en espiral define una serie de ciclos que se repiten en un bucle hasta el final del proyecto, dividiéndolo
en varias subtareas más sencillas y estableciendo puntos de control al final de cada iteraci\'on en los que se
evalúa el trabajo realizado y se enfocan las nuevas tareas para continuar.
Esta metodología recibe su nombre por la forma de espiral que tiene su representaci\'on gráfica o diagrama
de flujo, que podemos ver en la figura 2.1. En cada iteraci\'on se llevan a cabo las siguientes actividades:
Determinar los objetivos, dividir en subobjetivos y fijar requisitos.
Analizar los riesgos y factores que impidan o dificulten el trabajo y las consecuencias negativas
que este pueda ocasionar.

Para desarrollar las tareas especificadas en cada incremento, fijadas en cada reunión de seguimiento, se utilizó la metodología kanban. Esta metodología de desarrollo no es más que una adaptación de su versión industrial que surgió en Toyota. A finales de los años 40, Toyota empezó a optimizar sus procesos de ingeniería a partir del modelo que empleaban los supermercados para llenar los estantes. Los supermercados almacenan los productos suficientes para suplir la demanda del cliente, una práctica que optimiza el flujo entre el supermercado y el cliente. 
En su versión TIC ésta metodología se centra, al igual que su versión industrial, en el just in time y permite ver de una forma muy visual tas tareas que hay en vuelo, desarrolladas, pendientes o bloqueadas pudiendo anticiparnos a cuellos de botella o bloqueos de forma sencilla. Esta metodología nos permite visualizar tareas que a priori no tienen relación pero se relacionan a un nivel mas profundo y agruparlas para optimizar el tiempo.

\begin{figure}[h]
\centering
   \label{f:kanban}
    \includegraphics[width=0.31\textwidth]{img/IMG_0859.jpg}
   \label{f:espiral}
    \includegraphics[width=0.31\textwidth]{img/IMG_0864.jpg}
   \label{f:kanban}
    \includegraphics[width=0.31\textwidth]{img/IMG_0865.jpg}
   \label{f:kanban}
    \includegraphics[width=0.31\textwidth]{img/IMG_1016.jpg}
   \label{f:espiral}
    \includegraphics[width=0.31\textwidth]{img/IMG_1029.jpg}
   \label{f:kanban}
    \includegraphics[width=0.31\textwidth]{img/IMG_1037.jpg}
   \label{f:kanban}
    \includegraphics[width=0.31\textwidth]{img/IMG_1043.jpg}
   \label{f:espiral}
    \includegraphics[width=0.31\textwidth]{img/IMG_1249.jpg}
   \label{f:kanban}
    \includegraphics[width=0.31\textwidth]{img/IMG_0063.jpg}
\caption{Evolución de nuestra}
\end{figure}


Durante el ciclo de vida del proyecto se han llevado a cabo reuniones semanales de seguimiento con el tutor. En ellas
se evaluaban las tareas realizadas y se marcaba qué direcci\'on tomar para la siguiente iteración o incremento. Si los
puntos marcados en la anterior reuni\'on no se habían alcanzado se ampliaba el plazo o se discutían otras
vías para avanzar. En caso contrario se proponían nuevos subobjetivos.


Para apoyarnos en nuestro desarrollo hemos utilizado principalmente 4 herramientas:
\begin{itemize} 
\item GitHub como forja y control de versiones. En el repositorio https://github.com/RoboticsURJC-students/2014-pfc-JoseAntonio-Fernandez  se almacenan todos los desarrollos que son objetivo de éste PFC así como ésta memoria. También se encuentran subproductos de desarrollo que han ido surgiendo como apoyo o pruebas a los desarrollos principales.
\item Contamos también con un mediawiki en JdeRobot dónde hemos actualizado peri\'odicamente nuestros avances acompañados con explicaciones, vídeos e imágenes. Aquí se puede contemplar con mas detalle la construcción del UAV.
\item Como apoyo principalmente al mediawiki dispusimos de una carpeta en el FTP de JdeRobot hasta que colgamos los videos en Youtube.
\item Youtube. Muchos de los vídeos del mediawiki han sido compartidos en youtube.com.
\end{itemize}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% INFRAESTRUCTURA %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Infraestructura utilizada}
\label{chap:infraestructura_utilizada}

\section{Hardware}
\label{sec:hardware}

Este PFC se apoya principalmente en 2 piezas hardware:


\begin{itemize}
\item El avi\'on a radio-control. Para este desarrollo hemos elegido el avi\'on Bix3 distribuido por la empresa china \url{www.hobbyking.com}, hemos elegido este modelo por ser un avi\'on muy estable debido principalmente a sus cualidades como velero y su alta superficie alar. Otro aspecto importante de la constrcci\'on del avi\'on es que el propulsor no se encuentra en el frontal del avi\'on lo que nos permitirá aprovechar al máximo esa zona pudiendo poner incluso una cámara frontal.

\begin{figure}[h]
\centering
  \subfloat[Bix3]{
   \label{f:Bix3}
    \includegraphics[width=0.339\textwidth]{img/bix_general.jpg}}
  \subfloat[Vista de cerca]{
   \label{f:Vista de cerca}
    \includegraphics[width=0.339\textwidth]{img/bix_prof.jpg}}
  \subfloat[Bix3 en vuelo]{
   \label{f:Bix en vuelo}
    \includegraphics[width=0.3\textwidth]{img/bix_vuelo.png}}
 \label{f:drone_cano}
\end{figure}

Para poder cargar con el equipo necesario nos ha sido necesario cambiar el motor, el variador y las bater\'ias de serie por otras de mayor rendimiento que nos permitan volar con tanta carga de pago.

\item Una raspberry PI3 que es nuestro ordenador de abordo y en el que instalaremos la infraestructura necesaria para que podamos dotarle de inteligencia. Hemos elegido \'este dispositivo debido al compromiso peso/potencia que nos otorga as\'i como porque se trata de un hardware muy asequible  y extendido. Conectado a esta PI3 irá una PiCam que nos permitira ver lo que el avi\'on vea.
\end{itemize} 

\section{Placa estabilizadora}
\label{sec:estabilizadora}

El estabilizador/piloto autom\'atico, para este desarrollo hemos optado por un Ardupilot Mega\footnote{\url{http://www.ardupilot.co.uk/}}. Este dispositivo tiene como base una placa Arduino Mega a la que se le han incoorporado, gir\'oscopos y acerel\'ometros en 3 ejes para su estabilizaci\'on y que trae de serie un receptor GPS con br\'ujula. El kit que adquirimos incluye también también 
Esta placa ataca directamente sobre los actuadores del avi\'on (los servos y el motor) a trav\'es de señales PWM. 

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.50]{img/ardupilot.jpg}
  \caption{Placa estabilizadora ardupilot}
  \label{fig:ardupilot}
\end{figure}

Esta placa ha de flashearse con un firmware en funci\'on del tipo de aeronave que utilicemos como base, Arducoopter para alas rotatorias o Ardupilot para alas fijas.

Esta y otras placas similares como PixHawnk ofrecen un interfaz que se apoya en comandos llamado MAVLink. A trav\'es de comandos MAVLink se puede acceder a los sensores, a los que incoorpora la placa o a los que le añadamos a la misma como el GPS o sensores de velocidad del aire. A trav\'es de estos comandos se le puede tambi\'en enviar ordenes al piloto autom\'atico quien las ejecutar\'a más adelante trataremos el protocolo MAVLink en profundidad. Cabe sin embargo destacar ya en este punto no s\'olo que algunos de los comando que mandemos tendran distinto comportamiento en la placa en funcion del firmware escogido sino que hay set de comandos que no pueden ser utilizados en uno o en otro.


\section{JdeRobot}
\label{sec:jderobot}

JdeRobot es un framework desarrollado por el laboratorio de rob\'otica de la Universidad Rey Juan Carlos, para el desarrollo de aplicaciones de rob\'otica. Su última realease la 5.5 se liber\'o el 15 de Marzo de 2017 pudiendo ver los detalles de ésta en el github oficial\footnote{\url{https://github.com/JdeRobot/JdeRobot/wiki/JdeRobot-5.5.0}}.
JdeRobot se compone de interfaces, drivers, utilidades y aplicaciones para el desarrollo de cualquier proyecto de rob\'otica, se apoya en estos interfaces, algunos de ellos los veremos en profundidad a continuaci\'on, para interconectar entre sí todos los aplicativos del mismo y en Zeroc ICE para la comunicaci\'on entre ellos.
Algunos de los driver mas importantes que contiene serían:
\begin{enumerate}
\item Cameraserver. Se trata de un driver para enviar imágenes y video a través del interfaz camera
\item Gazeboserver. Driver desarrollado para conectar la herramienta de simulaci\'on Gazebo con JdeRobot y así poder simular los desarrollos.
\item MAVLinkServer. Desarrollado para intercomunicar JdeRobot con placas que utilicen el protocolo de comunicaci\'on MAVLink.
\item Ardrone\_server. Driver que conecta el Parrot Ar-Drone a JdeRobot. Este driver escrito en c++ transforma el set de comandos AT del done en interfaces y viceversa, implementa los interfaces camera, cmdvel, navdata, extra y pose3D y permite acceder a la actitud del drone así como a sus 2 cámaras. Sirve también datos como el nivel de la batería y permite grabar vídeo o tomar fotos.
\end{enumerate}
Algunas de las aplicaciones desarrolladas más importantes serían:
\begin{enumerate}
\item Cameraview. Se trata de una aplicaci\'on desarrollada en c++ capaz de recibir vídeo a través del interfaz camera.
\item UAV viewer. Aplicaci\'on desarrollada como ground control de robots aéreos. Esta aplicaci\'on permite teleoperar cualquier tipo de robot aéreo y ofrece de forma visualmente atractiva datos como la actitud, velocidades lineales y angulares, ofrece también la posibilidad de visualizar videos servidos por el interfaz camera.
\end{enumerate}
\subsection{Interfaces}

JdeRobot expone más de 30 interfaces pero en este cap\'itulo explicaremos los que durante nuestro desarrollo hemos implementado:
\begin{itemize}
\item Pose3D. Utilizado para recoger los datos de actitud y la posici\'on de la aeronave.
{\scriptsize
\begin{verbatim}
Pose3DData
  {
	float x;  /* x coord */
	float y;  /* y coord */
	float z;  /* z coord */
  	float h;  /* */
	float q0; /* qw */
	float q1; /* qx */
	float q2; /* qy */
	float q3; /* qz */
  };
\end{verbatim}}
\item Camera. Utilizado para servir im\'agenes.
{\scriptsize
\begin{verbatim}
  class CameraDescription
  {
    string name;
    string shortDescription;
    string streamingUri;
    float fdistx;
    float fdisty;
    float u0;
    float v0;
    float skew;
    float posx;
    float posy;
    float posz;
    float foax;
    float foay;
    float foaz;
    float roll;
  };

\end{verbatim}}
\item NavData. Utilizado para servir datos secundarios de actuaci\'on como velocidades lineales o angulares o el estado de la bater\'ia.
{\scriptsize
\begin{verbatim}
class NavdataData 
{
 int vehicle; //0-> ArDrone1, 1-> ArDrone2
 int state; // landed, flying,...
 float batteryPercent; //The remaing charge of baterry %
		
 //Magnetometer Ardron2.0
 int magX;
 int magY;
 int magZ;
		
 int pressure; //Barometer Ardron2.0
 int temp;     //Temperature sensor Ardron2.0
 float windSpeed; //Estimated wind speed Ardron2.0		
		
 float windAngle;
 float windCompAngle;
 
 float rotX; //rotation about the X axis
 float rotY; //rotation about the Y axis		
 float rotZ; //rotation about the Z axis
 
 int altd; //Estimated altitude (mm) 

 //linear velocities (mm/sec)
 float vx;
 float vy;
 float vz;
		
 //linear accelerations (unit: g) ¿Ardron2.0?
 float ax;
 float ay;
 float az;

 //Tags in Vision Detectoion
 //Should be unsigned
 int tagsCount;
 arrayInt tagsType;
 arrayInt tagsXc;
 arrayInt tagsYc;
 arrayInt tagsWidth;
 arrayInt tagsHeight;
 arrayFloat tagsOrientation;
 arrayFloat tagsDistance;

 float tm; //time stamp
};
\end{verbatim}}
\item Extra. Utilizado principalmente para las \'ordenes de despegue y aterrizaje.
{\scriptsize
\begin{verbatim}
    void land() - land drone. 
    void takeoff() - takeoff drone. 
    void reset() 
    void recordOnUsb(bool record) 
    void ledAnimation(int type,float duration, float req) 
    void flightAnimation(int type, float duration) 
    void flatTrim() 
    void toggleCam() - switch camera. 
\end{verbatim}}

\end{itemize}


\section{MAVLink}
\label{sec:mavlink}

MAVLink siglas de Micro Air Vehicle Link es un protocolo de comunicaci\'on desarrollado para comunicar las placas estabilizadoras con piloto automático a los GCS o Ground control station, las aplicaciones desde las que se podía enviar misiones y seguir el cumplimiento de las mismas desde tierra.
MAVLink se public\'o en 2009 por Lorenz Meier, publicado bajo licencia LGPL aspira a convertirse en el protocolo standard en rob\'otica aérea y se ha probado su funcionamiento en PX4, PIXHAWK, APM\footnote{Ardupilot Mega} y Parrot AR.Drone.

Un ejemplo de comando MAVLink ser\'ia:
{\scriptsize
\begin{verbatim}
type GpsStatus struct {
    SatellitesVisible  uint8      Némero de satélites visibles
    SatellitePrn       [20]uint8  Id Global de cada satélite
    SatelliteUsed      [20]uint8  Lista con el uso de cada satélite
    SatelliteElevation [20]uint8  Elevaci\'on, nos da el ángulo sobre el horizonte.
    SatelliteAzimuth   [20]uint8  Direcci\'on del satélite, 0: 0 grados, 255: 360 grados.
    SatelliteSnr       [20]uint8  Señal/ruido de cada uno de los satélites
}
\end{verbatim}}
Este mensaje trae la informaci\'on del enlace actual con el GPS y se env\'ia peri\'odicamente en ciclos que decidimos en par\'ametros de conexi\'on con el dispositivo.
Otro par\'ametro, esta vez vinculado a la actuaci\'on ser\'ia:
{\scriptsize
\begin{verbatim}
type MissionItem struct {
    Param1          float32    parámetro variable en funci\'on del comando.
    Param2          float32    parámetro variable en funci\'on del comando.
    Param3          float32    parámetro variable en funci\'on del comando.
    Param4          float32    parámetro variable en funci\'on del comando.
    X               float32    latitud
    Y               float32    longitud
    Z               float32    altitud
    Seq             uint16     Número del item en la misi\'on
    Command         uint16     Tipo de comando de navegaci\'on.
    TargetSystem    uint8      ID del sistema
    TargetComponent uint8      
    Frame           uint8      Sistema de coordenadas que se utiliza.
    Current         uint8      Misi\'on actual no:0, si:1
    Autocontinue    uint8      Autocontinuar al siguiente objeto de misi\'on.
}
\end{verbatim}}


\section{Python y PyQt5}
\label{sec:python}

Python es un lenguaje de programaci\'on interpretado y multiplataforma que naci\'o en los años 80 en los país bajos con idea de hacer más legible el c\'odigo.
El lenguaje de programaci\'on que inicialmente se utilizaba principalmente para scripting, ha sabido crecer con los años y con la publicaci\'on de Python3 en 2009 ha recibido el impulso que necesitaba para ser hoy en día el 5º leguaje mas utilizado por encima de PHP, .NET y Javascript que baja hasta el 8º puesto según TIOBE en un estudio de Abril de 2017.

El porqué de utlizar Python, muy sencillo mantiene el carácter multiplataforma de JdeRobot, su c\'odigo es simple y legible y trabaja muy bien con dependencias muy utilizadas en rob\'otica como OpenCV.

Para nuestro desarrollo hemos utilizado PyQt5 para desarrollar el interfaz gráfico. PyQt5 es un binding de Qt5 en forma de librería python que nos permite acceder a toda la funcionalidad de Qt5. Qt, propiedad de Nokia, es un conjunto de librerías escritas en C++ para interfaces gráficas.


\section{Mapas y Geo-referenciaci\'on}
\label{sec:mapas}

En nuestro desarrollo hemos tenido que trabajar con mapas geo-referenciados. Estos mapas, que tanto se han popularizado gracias a Google, son una herramienta imprescindible en rob\'otica aérea si se quiere trabajar con largas distancias.

Un mapa geo-referenciado es aquel en el que conocemos o podemos calcular la posici\'on en el planeta que representa cada pixel del mismo.

La forma mas común de obtener estos mapas geo-referenciado es a través de WMS, siglas de Web Map Service. Un WMS nos es mas que un servicio web que recibe como entrada unas coordenadas y una serie de parámetros y devuelve una imagen encuadrada en lo datos enviados.
En nuestro desarrollo hemos utilizado 2 WMS el del IGN\footnote{Instrituto Geográfico Nacional de españa} y el de Google, a continuaci\'on vamos a desgranar un WMS, el de PMOA del IGN.

El WMS PNOA requiere como entrada 4 atributos principales:
\begin{enumerate}
\item La posici\'on GPS.
\item Bounding Box. El Bounding box son 2 puntos que corresponden con la posici\'on GPS que queremos que sea el extremo inferior izquierdo de nuestra imagen y con el punto superior derecho de la misma.
\item Datum. El datum es el sistema de referencia o proyecci\'on de la tierra a utilizar. En el caso de IGN pese a que soporta varias utilizamos WGS84 que es el estandar.
\item Tamaño de la imagen, el tamaño que queremos que tenga la imagen obtenida.
\end{enumerate}
El resultado un mapa del que conocemos el punto central, y los extremos inferior izquierdo y superior derecho y los pixeles que tiene a lo ancho y alto del mismo, un mapa geo-referenciado.



\section{SITL}
\label{sec:SITL}

SITL siglas de Software in the loop es un simulador que te permite a cualquier programa que envíe o reciba comandos MAVLink ejecutar pruebas sin necesidad de tener ninguna placa estabilizadora y evitando la pérdida de la aeronave en caso de error del mismo.
SITL se conecta con JSBSim, un simulador de vuelo de software libre para ejecutar el aspecto físico de la simulaci\'on y con MAVProxy para el envío de commandos y seguimento de misiones.
Se trata de una compilaci\'on en C++ de ardupilot y se podría asemejar a nuestro gazeboserver.
SITL puede conectarse también con Gazebo o a FlightGear para hacer mas completa su simulaci\'on mostrando el vuelo en un entorno desarrollado para pruebas con elementos del mundo real.
\begin{figure}[H]
  \centering
  \includegraphics[scale=0.50]{img/SITL.jpg}
  \caption{Arquitectura de SITL}
  \label{fig:sitl}
\end{figure}

\cleardoublepage
\chapter{APM Server}


\section{Análisis y diseño} 
\label{sec:analisis_apms}

De un análisis exhaustivo definimos los requerimientos hablados en el capítulo 2.1.2 y que serían a grandes rasgos:
\begin{itemize}
\item El driver debe ser capaz de conectar con dispositivos físicos de estabilización cómo APM 2.8 o PixHawnk así como al simulador SITL
\item El driver debe acceder a los sensores y actuadores del robot aéreo, interpretarlos y servirlos en forma de interfaz.
\item EL driver debe ser capar de recibir a través de interfaces JdeRobot interfaces que éste interprete y envíe a los actuadores del robot aéreo.
\end{itemize}

Para abordar este desarrollo vamos a definir 3 capas que pasamos a describir desde la más cercana al hardware hasta la más cercana a JdeRobot:
\begin{itemize}
\item Capa de comunicación con el dispositivo APM. Esta capa se encargará de la comunicación del driver con el dispositivo APM a través del protocolo de comunicación MavLink.
\item Capa de negocio e interpretación. En esta capa el driver transformará los comandos MavLink y los interfaces JdeRobot interpretando la información de ambas capas y haciendo ésta legible en ambos sentidos.
\item Capa de comunicación con JdeRobot. En ésta capa se expondrán los servicios Ice necesarios para la recepción y envío de los interfaces Ice que implementa.
\end{itemize}

\section{Interfaces} 
\label{sec:interfaces_apms}

\subsection{Comunicación APM}
En la capa de comunicación con el APM dónde recibimos comandos MAVLink vamos a consumir y enviar los siguientes mensajes:
\begin{itemize}
\item RAW\_IMU donde recibiremos la información de los acelerómetros giróscopos y magnetrómetros en crudo par el NavData.
{\scriptsize
\begin{verbatim}
<message id="27" name="RAW_IMU">
  <description>The RAW IMU readings for the usual 9DOF sensor setup. 
    This message should alwaysCcontain the true raw values without any
    scaling to allow data capture and system debugging.</description>
  <field type="uint64_t" name="time_usec" units="us">Timestamp 
    (microseconds since UNIX epoch or microseconds since system boot)</field>
  <field type="int16_t" name="xacc">X acceleration (raw)</field>
  <field type="int16_t" name="yacc">Y acceleration (raw)</field>
  <field type="int16_t" name="zacc">Z acceleration (raw)</field>
  <field type="int16_t" name="xgyro">Angular speed around X axis (raw)</field>
  <field type="int16_t" name="ygyro">Angular speed around Y axis (raw)</field>
  <field type="int16_t" name="zgyro">Angular speed around Z axis (raw)</field>
  <field type="int16_t" name="xmag">X Magnetic field (raw)</field>
  <field type="int16_t" name="ymag">Y Magnetic field (raw)</field>
  <field type="int16_t" name="zmag">Z Magnetic field (raw)</field>
</message>
\end{verbatim}}
Un mensaje recibido sería: 
RAW\_IMU \{time\_usec : 480794000, xacc : 244, yacc : 0, zacc : -968, xgyro : 1, ygyro : 1, zgyro : 1, xmag : 335, ymag : 60, zmag : -452\}

\item VFR\_HUD Dónde se nos presentan los típicos datos de navegación en ala fija como, la velocidad en el aire, velocidad en tierra o la velocidad de ascenso. De aquí obtendremos la altitud
{\scriptsize
\begin{verbatim}
<message id="74" name="VFR_HUD">
  <description>Metrics typically displayed on a HUD for fixed wing aircraft</description>
  <field type="float" name="airspeed" units="m/s">Current airspeed in m/s</field>
  <field type="float" name="groundspeed" units="m/s">Current ground speed in m/s</field>
  <field type="int16_t" name="heading" units="deg">Current heading in degrees, 
    in compass units (0..360, 0=north)</field>
  <field type="uint16_t" name="throttle" units="%">Current throttle setting in 
    integer percent, 0 to 100</field>
  <field type="float" name="alt" units="m">Current altitude (MSL), in meters</field>
  <field type="float" name="climb" units="m/s">Current climb rate in meters/second</field>
</message>
\end{verbatim}}
Un mensaje recibido sería: VFR\_HUD \{airspeed : 0.022061701864004135, groundspeed : 0.08534427732229233, heading : 356, throttle : 0, alt : 584.1099853515625, climb : -0.33149993419647217\} 
\item ATTITUDE donde recibimos la actitud del avión.
{\scriptsize
\begin{verbatim}
<message id="30" name="ATTITUDE">
  <description>The attitude in the aeronautical frame 
    (right-handed, Z-down, X-front, Y-right).</description>
  <field type="uint32_t" name="time_boot_ms" units="ms">Timestamp 
    (milliseconds since system boot)</field>
  <field type="float" name="roll" units="rad">Roll angle (rad, -pi..+pi)</field>
  <field type="float" name="pitch" units="rad">Pitch angle (rad, -pi..+pi)</field>
  <field type="float" name="yaw" units="rad">Yaw angle (rad, -pi..+pi)</field>
  <field type="float" name="rollspeed" units="rad/s">Roll angular speed (rad/s)</field>
  <field type="float" name="pitchspeed" units="rad/s">Pitch angular speed (rad/s)</field>
  <field type="float" name="yawspeed" units="rad/s">Yaw angular speed (rad/s)</field>
</message>
\end{verbatim}}
Un mensaje recibido sería:
ATTITUDE \{time\_boot\_ms : 480794, roll : -0.005003694910556078, pitch : 0.2430807501077652, yaw : -0.06844368577003479, rollspeed : -0.0010073177982121706, pitchspeed : -0.0008516315137967467, yawspeed : -0.0006909647490829229\}

\item SYS\_STATUS donde obtendremos el nivel de batería.
{\scriptsize
\begin{verbatim}
<message id="1" name="SYS_STATUS">
  <description>The general system state. If the system is following the MAVLink standard, 
    the system state is mainly defined by three orthogonal states/modes: The system mode, 
    which is either LOCKED (motors shut down and locked), MANUAL (system under RC control), 
    GUIDED (system with autonomous position control, position setpoint controlled manually) 
    or AUTO (system guided by path/waypoint planner). 
    The NAV_MODE defined the current flight state: 
      LIFTOFF (often an open-loop maneuver), 
      LANDING
      WAYPOINTS
      VECTOR. 
    This represents the internal navigation state machine. The system status shows wether 
    the system is currently active or not and if an emergency occured. 
    During the CRITICAL and EMERGENCY states the MAV is still considered to be active, 
    but should start emergency procedures autonomously. After a failure occured it should 
    first move from active to critical to allow manual intervention and then move to 
    emergency after a certain timeout.</description>
  <field type="uint32_t" name="onboard_control_sensors_present" enum="MAV_SYS_STATUS_SENSOR" 
    display="bitmask" print_format="0x%04x">
    Bitmask showing which onboard controllers and sensors are present. Value of 0: not 
    present. Value of 1: present. Indices defined by ENUM MAV_SYS_STATUS_SENSOR</field>
  <field type="uint32_t" name="onboard_control_sensors_enabled" enum="MAV_SYS_STATUS_SENSOR" 
    display="bitmask" print_format="0x%04x">
    Bitmask showing which onboard controllers and sensors are enabled:  Value of 0: 
    not enabled. Value of 1: enabled. Indices defined by ENUM MAV_SYS_STATUS_SENSOR</field>
  <field type="uint32_t" name="onboard_control_sensors_health" enum="MAV_SYS_STATUS_SENSOR" 
    display="bitmask" print_format="0x%04x">
    Bitmask showing which onboard controllers and sensors are operational or have an error:  
    Value of 0: not enabled. Value of 1: enabled. 
    Indices defined by ENUM MAV_SYS_STATUS_SENSOR</field>
  <field type="uint16_t" name="load" units="d%">Maximum usage in percent of the mainloop 
    time, (0%: 0, 100%: 1000) should be always below 1000</field>
  <field type="uint16_t" name="voltage_battery" units="mV">Battery voltage, in millivolts 
    (1 = 1 millivolt)</field>
  <field type="int16_t" name="current_battery" units="cA">Battery current, in 
    10*milliamperes (1 = 10 milliampere), -1: autopilot does not measure the current</field>
  <field type="int8_t" name="battery_remaining" units="%">Remaining battery energy: 
    (0%: 0, 100%: 100), -1: autopilot estimate the remaining battery</field>
  <field type="uint16_t" name="drop_rate_comm" units="c%">Communication drops in percent, 
    (0%: 0, 100%: 10'000), (UART, I2C, SPI, CAN), dropped packets on all links 
    (packets that were corrupted on reception on the MAV)</field>
  <field type="uint16_t" name="errors_comm">Communication errors (UART, I2C, SPI, CAN), 
    dropped packets on all links (packets that were corrupted on reception on the MAV)</field>
      <field type="uint16_t" name="errors_count1">Autopilot-specific errors</field>
      <field type="uint16_t" name="errors_count2">Autopilot-specific errors</field>
      <field type="uint16_t" name="errors_count3">Autopilot-specific errors</field>
      <field type="uint16_t" name="errors_count4">Autopilot-specific errors</field>
</message>
\end{verbatim}}
Un mensaje recibido sería: 
SYS\_STATUS \{onboard\_control\_sensors\_present : 23198783, onboard\_control\_sensors\_enabled : 23198783, onboard\_control\_sensors\_health : 24247359, load : 0, voltage\_battery : 12587, current\_battery : 0, battery\_remaining : 100, drop\_rate\_comm : 0, errors\_comm : 0, errors\_count1 : 0, errors\_count2 : 0, errors\_count3 : 0, errors\_count4 : 0\}
\item SCALED\_PRESSURE donde obtendremos la presión absoluta y la temperatura.
{\scriptsize
\begin{verbatim}
<message id="29" name="SCALED_PRESSURE">
  <description>The pressure readings for the typical setup of one absolute and differential 
      pressure sensor. The units are as specified in each field.</description>
  <field type="uint32_t" name="time_boot_ms" units="ms">Timestamp 
      (milliseconds since system boot)</field>
  <field type="float" name="press_abs" units="hPa">Absolute pressure (hectopascal)</field>
  <field type="float" name="press_diff" units="hPa">Differential pressure 1 </field>
  <field type="int16_t" name="temperature" units="cdegC">Temperature measurement 
     (0.01 degrees celsius)</field>
</message>
\end{verbatim}}
Un mensaje recibido sería: 
SCALED\_PRESSURE \{time\_boot\_ms : 480794, press\_abs : 945.0001831054688, press\_diff : 0.021015625447034836, temperature : 2600\}
\item WIND donde obtendemos las lecturas del viento estimadas.
{\scriptsize
\begin{verbatim}
<message id="168" name="WIND">
    <description>Wind estimation</description>
    <field name="direction" type="float">wind direction that wind is coming from </field>
    <field name="speed" type="float">wind speed in ground plane (m/s)</field>
    <field name="speed_z" type="float">vertical wind speed (m/s)</field>
</message>
\end{verbatim}}
Un mensaje recibido sería: 
WIND \{direction : -179.99998474121094, speed : 0.0, speed\_z : 0.0\}
\item GLOBAL\_POSITION\_INT donde obtendremos la posición GPS.
{\scriptsize
\begin{verbatim}
<message id="33" name="GLOBAL_POSITION_INT">
  <description>The filtered global position (e.g. fused GPS and accelerometers). 
    The position is in GPS-frame (right-handed, Z-up). It is designed as scaled integer 
    message since the resolution of float is not sufficient.</description>
  <field type="uint32_t" name="time_boot_ms" units="ms">Timestamp 
    (milliseconds since system boot)</field>
  <field type="int32_t" name="lat" units="degE7">Latitude, expressed as degrees * 1E7</field>
  <field type="int32_t" name="lon" units="degE7">Longitude, expressed as degrees * 1E7</field>
  <field type="int32_t" name="alt" units="mm">Altitude in meters, expressed as 
    * 1000 (millimeters), AMSL (not WGS84 - note that virtually all GPS modules provide 
    the AMSL as well)</field>
  <field type="int32_t" name="relative_alt" units="mm">Altitude above ground in meters,
    expressed as * 1000 (millimeters)</field>
  <field type="int16_t" name="vx" units="cm/s">Ground X Speed (Latitude, positive north), 
    expressed as m/s * 100</field>
  <field type="int16_t" name="vy" units="cm/s">Ground Y Speed (Longitude, positive east), 
    expressed as m/s * 100</field>
  <field type="int16_t" name="vz" units="cm/s">Ground Z Speed (Altitude, positive down), 
    expressed as m/s * 100</field>
  <field type="uint16_t" name="hdg" units="cdeg">Vehicle heading (yaw angle) in degrees 
    * 100, 0.0..359.99 degrees. If unknown, set to: UINT16_MAX</field>
</message>
\end{verbatim}}
Un mensaje recibido sería: 
GLOBAL\_POSITION\_INT \{time\_boot\_ms : 480614, lat : -353632612, lon : 1491652301, alt : 584110, relative\_alt : -179, vx : 0, vy : 0, vz : 0, hdg : 35608\}
\item MISSION\_ITEM Son objetos de misión, en ellos se mandan los Waypoint o comandos como setear una velocidad o una altitud o bien aterrizar o desapegar en función del parámetro command.
{\scriptsize
\begin{verbatim}
<message id="39" name="MISSION_ITEM">
  <description>Message encoding a mission item. This message is emitted to announce the 
    presence of a mission item and to set a mission item on the system. The mission item 
    can be either in x, y, z meters (type: LOCAL) or x:lat, y:lon, z:altitude. 
    Local frame is Z-down, right handed (NED), global frame is Z-up, right handed (ENU). 
    See also http://qgroundcontrol.org/mavlink/waypoint_protocol.</description>
  <field type="uint8_t" name="target_system">System ID</field>
  <field type="uint8_t" name="target_component">Component ID</field>
  <field type="uint16_t" name="seq">Sequence</field>
  <field type="uint8_t" name="frame" enum="MAV_FRAME">The coordinate system of the MISSION. 
    see MAV_FRAME in mavlink_types.h</field>
  <field type="uint16_t" name="command" enum="MAV_CMD">The scheduled action for the MISSION. 
    see MAV_CMD in common.xml MAVLink specs</field>
  <field type="uint8_t" name="current">false:0, true:1</field>
  <field type="uint8_t" name="autocontinue">autocontinue to next wp</field>
  <field type="float" name="param1">PARAM1, see MAV_CMD enum</field>
  <field type="float" name="param2">PARAM2, see MAV_CMD enum</field>
  <field type="float" name="param3">PARAM3, see MAV_CMD enum</field>
  <field type="float" name="param4">PARAM4, see MAV_CMD enum</field>
  <field type="float" name="x">PARAM5 / local: x position, global: latitude</field>
  <field type="float" name="y">PARAM6 / y position: global: longitude</field>
  <field type="float" name="z">PARAM7 / z position: global: altitude (relative or absolute,
    depending on frame.</field>
  <extensions/>
  <field type="uint8_t" name="mission_type" enum="MAV_MISSION_TYPE">Mission type, 
    see MAV_MISSION_TYPE</field>
</message>
\end{verbatim}}
Un mensaje enviado sería: MISSION\_ITEM \{target\_system : 1, target\_component : 1, seq : 0, frame : 3, command : 16, current : 0, autocontinue : 0, param1 : 0, param2 : 10, param3 : 0, param4 : 0, x : 40.33024215698242, y : -3.8008816242218018, z : 40.0\}
\item MISSION\_REQUEST mesaje donde el AMP nos requiere el siguiente MISSION\_ITEM. Este comando se recibe o bien una ver enviado al APM nuestra intención de enviale mensajes de misión y cuando vamos a enviarle, en un comando MISSION\_COUNT o bien tras la recepción de alguno de ellos como ACK y solicitando el siguiente
{\scriptsize
\begin{verbatim}
<message id="40" name="MISSION_REQUEST">
  <description>Request the information of the mission item with the sequence number seq. 
    The response of the system to this message should be a MISSION_ITEM message. 
    http://qgroundcontrol.org/mavlink/waypoint_protocol</description>
  <field type="uint8_t" name="target_system">System ID</field>
  <field type="uint8_t" name="target_component">Component ID</field>
  <field type="uint16_t" name="seq">Sequence</field>
  <extensions/>
  <field type="uint8_t" name="mission_type" enum="MAV_MISSION_TYPE">Mission type, 
    see MAV_MISSION_TYPE</field>
</message>
\end{verbatim}}
Un mensaje recibido sería: MISSION\_REQUEST \{target\_system : 0, target\_component : 0, seq : 2\} En este mensaje el APM nos estaría solicitando el item de misión 3, ya que empieza solicitando el 0. Este mensaje termina al llegar al máximo de mission item que hemos indicado que le vamos a mandar 

\item MISSION\_COUNT éste comando se envía para comenzar una comunicación con el APM con el objetivo de enviarle una misión.
{\scriptsize
\begin{verbatim}
<message id="44" name="MISSION_COUNT">
  <description>This message is emitted as response to MISSION_REQUEST_LIST by the MAV
    and to initiate a write transaction. The GCS can then request the individual
    mission item based on the knowledge of the total number of MISSIONs.</description>
  <field type="uint8_t" name="target_system">System ID</field>
  <field type="uint8_t" name="target_component">Component ID</field>
  <field type="uint16_t" name="count">Number of mission items in the sequence</field>
  <extensions/>
  <field type="uint8_t" name="mission_type" enum="MAV_MISSION_TYPE">Mission type, 
    see MAV_MISSION_TYPE</field>
</message>
\end{verbatim}}
Un mensaje enviado sería: MISSION\_COUNT \{target\_system : 0, target\_component : 0, count : 3\} Donde comunicamos al APM nuestra intención de enviarle 3 objetos de misión.

\item MISSION\_CLEAR\_ALL éste comando sirve para limpiar el APM de misiones, si éste tenía alguna misión previa se desecha.
{\scriptsize
\begin{verbatim}
<message id="45" name="MISSION_CLEAR_ALL">
  <description>Delete all mission items at once.</description>
  <field type="uint8_t" name="target_system">System ID</field>
  <field type="uint8_t" name="target_component">Component ID</field>
  <extensions/>
  <field type="uint8_t" name="mission_type" enum="MAV_MISSION_TYPE">Mission type, 
    see MAV_MISSION_TYPE</field>
</message>
\end{verbatim}}
Un mesaje enviado sería MISSION\_CLEAR\_ALL \{target\_system : 0, target\_component : 0\}
\end{itemize}

\subsection{Comunicación JdeRobot}

En la comunicación con JdeRobot vamos a utilizar los interfaces descritos en el capítulo 3.1.1:
\begin{itemize}
\item Pose3D
\item NavData
\item Extra
\item Camera
\end{itemize}

Y adicionalmente un nuevo interfaz que hemos desarrollado para dar soporte al uso de misiones, el interfaz mission.
{\scriptsize
\begin{verbatim}
class Pose3DData  //we consumes Pose3DData
  {
		float x;
		float y;
		float z;
  	float h;
		float q0;
		float q1;
		float q2;
		float q3;
  };

  ["python:seq:list"] sequence<Pose3DData> PoseSequence;
  /**
  * Mission data information 
  */
  class MissionData
  {
    PoseSequence mission;
  };

  /** 
   * Interface to the Mission.
   */
  interface Mission
  {
    idempotent MissionData getMissionData();
    int setMissionData(MissionData data);
  };
\end{verbatim}}
\section{Implementación} 
\label{sec:impl_apms}

Para en tender mejor el código que vamos a describir a continuación se muestra un esquema del diseño del driver. 

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.30]{img/Attachment-1.png}
  \caption{Diseño de APM Server}
  \label{fig:apms_design}
\end{figure}

\subsection{Capa de conexión MAVLink}

\subsubsection{Conexión y configuración}

De cara a facilitarnos la implementación del software, ahorrarnos crear los comandos MAVLink a mano y hacer el código más legible utlizaremos las librería pymavlink. Con pymavlink podemos traernos ya a python la definición de los comandos a utilizar con los import siguientes.
Importamos mavutil para ardupilotmega para obtener los interfaces en python gracias a pymavlink y mavwp y quaternion para ayudarnos con la transformación a quaterniones.

\begin{python}[
    basicstyle=\scriptsize, %or \small or \footnotesize etc.
]
from pymavlink import mavutil, quaternion, mavwp
from pymavlink.dialects.v10 import ardupilotmega as mavlink
\end{python}


El primer paso para poder interactuar con el APM es el proceso de conexión. En el comando de conexión se le indica una de las siguiente tuplas:
\begin{itemize}
\item Dispositivo\_serie, baudrate
\item Tipo\_de\_puerto:IP:puerto, baudrate. En este caso baudrate es obligatorio pero se desecha.
\end{itemize}


\begin{python}[
    basicstyle=\scriptsize, %or \small or \footnotesize etc.
]
class Server:

    def __init__(self, port, baudrate):

        # Connect to the APM
        self.master = mavutil.mavlink_connection(port, baudrate, autoreconnect=True)
        print('Connection established to device')

	#Waiting for a HeartBeat
        self.master.wait_heartbeat()
        print("Heartbeat Recieved")

#test = Server("/dev/ttyUSB0", 57600)
test = Server("udp:192.168.1.133:14558",57600)
\end{python}

Con estas líneas iniciamos nuestro servidor y conectamos con él y podemos apreciar en la creación del servidor 2 conexiones, la comentada sería al dispositivo real y la que se encuentran sin comentar a SITL.

Una vez conectado, debemos indicar al APM qué mensajes queremos recibir y la frecuencia con la que queremos recibirlo. Debido a que se trata de un prototipo y estamos tratando de extraer el máximo potencial del mismo indicaremos el set de instrucciones completo y una frecuencia de moderada a alta 50 hz, lo máximo que soporta nuestro APM.
\begin{python}[
    basicstyle=\scriptsize, %or \small or \footnotesize etc.
]
	RATE = 50

        # Set the complete set of commands
        self.master.mav.request_data_stream_send(self.master.target_system,
                                                 self.master.target_component,
                                                 mavutil.mavlink.MAV_DATA_STREAM_ALL,
                                                 RATE, 1)
\end{python}

Desde éste momento se van a estar volcando a un buffer los mensajes que manda nuestro APM, con lo que ahora ya podemos acceder a ellos para procesarlos.

\subsubsection{Lectura de datos del APM}

Una vez establecida la conexión y seteados los parámetros de configuración ya podemos acceder a los datos. Para ésto en nuestra capa de transformación se levantará el siguiente hilo que procesará los mensajes

\begin{python}[
    basicstyle=\scriptsize, %or \small or \footnotesize etc.
]
# Thread to manage the AMP messages
MsgHandler = threading.Thread(target=self.mavMsgHandler, args=(self.master,), name='msg_Handler')
print('Initiating server...')
# MsgHandler.daemon = True
MsgHandler.start()

	def mavMsgHandler(self, m):
	"""
	Funtion who handle the mavLink's messages received and refresh the attitude
	:param m: mavLink Connector
	:return: none
	"""
	while True:
	    msg = m.recv_msg()
	    # send heartbeats to autopilot
	    if time.time() - self.lastSentHeartbeat > 1.0:
		self.master.mav.heartbeat_send(mavlink.MAV_TYPE_GCS, mavlink.MAV_AUTOPILOT_INVALID, 0, 0, 0)
		self.lastSentHeartbeat = time.time()

		# refresh the attitude
		self.refreshAPMPose3D()
		self.refreshAPMnavdata()

	    elif msg is None or msg.get_type() == "BAD_DATA":
		time.sleep(0.01)
		continue

\end{python}

En este thread e accede a los mensajes para su procesamiento, salvo que no se haya recibido ninguno aún, en los métodos refreshAPMPose3D() y refreshAPMnavdata().

\subsubsection{Envío de misiones al APM}

Con el fin de entender mejor el código en la figura 4.2 podemos observar un gráfico de cómo es el protocolo de envío de misiones al APM a través de MAVLink obtenido de la universidad University of Colorado Boulder\cite{colorado:_mission}
\begin{figure}[H]
  \centering
  \includegraphics[scale=0.70]{img/waypoint-protocol-sendlist.png}
  \caption{Protocolo de envío de misiones MAVLink}
  \label{fig:misiones_mavlink}
\end{figure}

Para abordar el problema e implementar dicho protocolo partimos de la solución que nos propone la Universidad de Colorado Boulder\cite{colorado:_mission} y la adaptamos a nuestras necesidades recibiendo de entrada un objeto de la interfaz mission de JdeRobot, transformándolo y enviándolo como misión. También revisamos si se nos han enviado órdenes de despegue y aterrizaje y en el caso de que así sea añadimos sus mission item al principio o al final de la missión. En éste punto se entrelazan la capa de interpretación con la capa de comunicación con el APM


\begin{python}[
    basicstyle=\scriptsize, %or \small or \footnotesize etc.
]


    def setMission(self, mission):
        '''
        SetUp a mission with a list of waypoints, based on Colorado University Boulder Code
        http://www.colorado.edu/recuv/2015/05/25/mavlink-protocol-waypoints
        :param pose3Dwaypoints: list of waypoints to the mission
        :return: None
        '''
        wp = mavwp.MAVWPLoader()
        seq = 1
        frame = mavutil.mavlink.MAV_FRAME_GLOBAL_RELATIVE_ALT
        radius = 10
        pose3Dwaypoints = mission.mission
        print("waypoints received {0}" ,len(pose3Dwaypoints))
        print(self.extra.takeOffDecision)
        N = len(pose3Dwaypoints)
        # Look if a Take Off message has been recieved to set up in the mission too, Take off must to be
        # the fist so if we have the TOFF message we have to create the message and start the loop in 1
        if (self.extra.takeOffDecision):
            navData = pose3Dwaypoints[seq-1]
            toff = mavutil.mavlink.MAVLink_mission_item_message(self.master.target_system,
                                                                self.master.target_component,
                                                                seq,
                                                                frame,
                                                                mavutil.mavlink.MAV_CMD_NAV_TAKEOFF, # 22
                                                                0, 0, 0, radius, 0, 0,
                                                                navData.x, navData.y, navData.h)
            wp.add(toff)
            wp.add(toff)
            print(toff)
            seq += 1
            self.extra.setTakeOff(False)
        self.extra.setTakeOff(False)

        for i in range(N):
            navData = pose3Dwaypoints[i]
            wayPoint_tmp =mavutil.mavlink.MAVLink_mission_item_message(self.master.target_system,
                                                                self.master.target_component,
                                                                seq,
                                                                frame,
                                                                mavutil.mavlink.MAV_CMD_NAV_WAYPOINT, # 16
                                                                0, 0, 0, radius, 0, 0,
                                                                navData.x, navData.y, navData.h)
            wp.add(wayPoint_tmp)
            seq += 1
            print(wayPoint_tmp)

        # Look if a land message has been recieved to set up in the mission too, Land must to be
        # the last so if we have the land message we have to create the message and append to the mission
        print("Land ", self.extra.landDecision)
        if (self.extra.landDecision):
            navData = pose3Dwaypoints[N-1]
            land = mavutil.mavlink.MAVLink_mission_item_message(self.master.target_system,
                                                                self.master.target_component,
                                                                seq,
                                                                frame,
                                                                mavutil.mavlink.MAV_CMD_NAV_LAND, # 21
                                                                0, 0, 0, radius, 0, 0,
                                                                navData.x, navData.y, navData.h)
            seq += 1
            i += 1
            wp.add(land)
            print(land)


        self.master.waypoint_clear_all_send()
        self.master.waypoint_count_send(wp.count())

        for i in range(wp.count()):
            msg = self.master.recv_match(type=['MISSION_REQUEST'], blocking=True)
            print(msg)
            self.master.mav.send(wp.wp(i))
            print ('Sending waypoint {0} '.format(i) + format(wp.wp(msg.seq)))

        self.master.arducopter_arm()
        self.master.set_mode_auto() # arms and start mission I thought

        print('SENDED')
        empty_mission = jderobot.MissionData()
        self.mission.setMissionData(empty_mission)

\end{python}

\subsection{Capa de interpretación}

En ésta capa se interpretan los mensajes recibidos de una y otra capa y se transforman en el formato que sea necesario para que o interprete la opuesta.


El método setMission() se llama al recibir vía Ice una mission. Para identificar cuando llega, debido a que tenemos mapeados las variables con Ice, hemos construido un listener que valida el valor de la variable mission y si tiene contenido articula el método setMission(mission).

\begin{python}[
    basicstyle=\scriptsize, %or \small or \footnotesize etc.
]
    print("- Mission listener")
    MissionListener = threading.Thread(target=self.missionListener, name='MissionListener')
    MissionListener.daemon = True
    MissionListener.start()
    print("Mission listener up")


    def missionListener(self):
        '''
        Function who listen to a new mission revieved from Ice MissionChannel thread and send it to APM
        :return: None
        '''
        while True:
            if not self.mission.is_empty():
                self.lastMission = self.mission
                self.setMission(self.mission.getMissionData())

            time.sleep(1)

\end{python}
Ya hemos visto cómo se realiza la transformación entre mensajes de misión en el método setMission(mission), ahora nos centraremos en interpretar los mensajes recibidos del APM y crear los objetos de las interfaces que sean necesarias para su interpretación por JdeRobot.
Esto lo realizamos principalmente en 2 métodos, refreshAPMPose3D() y refreshAPMnavdata().
Estos métodos se centran en buscar dentro de los paquetes recibidos aquellos que contienen informción relevante para nosotros, ya descritos en el capítulo 4.2, parsearlos y extraer de ellos la información que necesitamos y guardarla en objetos de interfaces JdeRobot para ser servidos a través de Ice.

\begin{python}[
    basicstyle=\scriptsize, %or \small or \footnotesize etc.
]
    def refreshAPMPose3D(self):
        """
        Funtion to refresh the Pose3D class atribute
        :return: none
        """

        # get attitude of APM
        if 'ATTITUDE' not in self.master.messages:
            self.attitudeStatus = 1
            q=[0,0,0,0]
        else:
            attitude = self.master.messages['ATTITUDE']
            # print(attitude)
            yaw = getattr(attitude,"yaw")
            pitch = getattr(attitude,"pitch") * -1
            roll = getattr(attitude,"roll")
            q = quaternion.Quaternion([roll, pitch, yaw])

        # get altitude of APM
        altitude = self.master.field('VFR_HUD', 'alt', None)
        if altitude is None:
            self.altitudeStatus = 1

        # get GPS position from APM
        latitude = 0
        longitude = 0
        if 'GPS_RAW_INT' not in self.master.messages:
            self.gpsStatus = 1
        else:
            gps = self.master.messages['GPS_RAW_INT']

            latitude = getattr(gps,"lat")/ 10e6
            longitude = getattr(gps,"lon") / 10e6
            self.GPS_fix_type = getattr(gps,"fix_type")

        # refresh the pose3D
        data = jderobot.Pose3DData
        data.x = latitude
        data.y = longitude
        data.z = altitude
        data.h = altitude
        data.q0 = q.__getitem__(0)
        data.q1 = q.__getitem__(1)
        data.q2 = q.__getitem__(2)
        data.q3 = q.__getitem__(3)
        self.pose3D.setPose3DData(data)

    def refreshAPMnavdata(self):
        """
        Function that apdate
        :return: none
        """
        battery_remaining = 0
        rawIMU = {}
        scaled_presure = {}
        wind = {}
        global_position = {}


        #get battery_remaining
        if 'SYS_STATUS' not in self.master.messages:
            self.battery_remainingStatus = 1
        else:
            stats = self.master.messages['SYS_STATUS']
            battery_remaining = getattr(stats,"battery_remaining")

        #get RAW_IMU
        if 'RAW_IMU' not in self.master.messages:
            self.rawIMUStatus = 1
        else:
            rawIMU = self.master.messages['RAW_IMU']

        #get SCALED PRESSURE
        if 'SCALED_PRESSURE' not in self.master.messages:
            self.scaled_presureStatus = 1
        else:
            scaled_presure = self.master.messages['SCALED_PRESSURE']

        #get WIND
        if 'WIND' not in self.master.messages:
            self.gpsStatus = 1
        else:
            wind = self.master.messages['WIND']

        #get GLOBAL_POSITION_INT
        if 'GLOBAL_POSITION_INT' not in self.master.messages:
            self.gpsStatus = 1
        else:
            global_position = self.master.messages['GLOBAL_POSITION_INT']

        # refresh the navdata
        ndata = jderobot.NavdataData()

        ndata.batteryPercent = battery_remaining
        #print(str(ndata.batteryPercent))
        try:
            ndata.pressure = getattr(scaled_presure, "press_abs")
        except:
            print (str(scaled_presure))
        try:
            ndata.temp = getattr(scaled_presure, "temperature")/100
        except:
            print(str(scaled_presure))
        try:
            ndata.windSpeed = getattr(wind, "speed")
        except:
            print(str(wind))
        try:
            ndata.windAngle = getattr(wind, "direction")
        except:
            print(str(wind))
        try:
            ndata.vx = getattr(global_position, "vx")
        except:
            print(str(global_position))
        try:
            ndata.vy = getattr(global_position, "vy")
        except:
            print(str(global_position))
        try:
            ndata.vz = getattr(global_position, "vz")
        except:
            print(str(global_position))
        try:
            ndata.rotx = getattr(rawIMU, "xgyro")
        except:
            print(str(rawIMU))
        try:
            ndata.roty = getattr(rawIMU, "ygyro")
        except:
            print(str(rawIMU))
        try:
            ndata.rotz = getattr(rawIMU, "zgyro")
        except:
            print(str(rawIMU))
        try:
            ndata.ax = getattr(rawIMU, "xacc")
        except:
            print(str(rawIMU))
        try:
            ndata.ay = getattr(rawIMU, "yacc")
        except:
            print(str(rawIMU))
        try:
            ndata.az = getattr(rawIMU, "zacc")
        except:
            print(str(rawIMU))
        try:
            ndata.magx = getattr(rawIMU, "xmag")
        except:
            print(str(rawIMU))
        try:
            ndata.magy = getattr(rawIMU, "ymag")
        except:
            print(str(rawIMU))
        try:
            ndata.magz = getattr(rawIMU, "zmag")
        except:
            print(str(rawIMU))

        ndata.tagsCount = 0
        ndata.tagsType
        ndata.tagsXc
        ndata.tagsYc
        ndata.tagsWidth
        ndata.tagsHeight
        ndata.tagsOrientation
        ndata.tagsDistance
        ndata.vehicle = 1
        ndata.state = 1

        self.navdata.setNavdata(ndata)

\end{python}

\subsection{Capa de comunicación con JdeRobot}

En ésta capa servimos y recibimos los objetos de interfaces JdeRobot de modo que sean entendibles por el resto des framework.
Para ésto tenemos 4 hilos, uno por cada interfaz JdeRobot que recibo o sirvo. En éstos hilos levantamos un servidor Ice para recibir o servir objetos de interfaces JdeRobot mapeando atribulos de la clase del servidor al estos servicios Ice.

\begin{python}[
    basicstyle=\scriptsize, %or \small or \footnotesize etc.
]
        # Thread to serve Pose3D with the attitude
        print("- Pose3D Ice Server...")
        PoseTheading = threading.Thread(target=self.openPose3DChannel, args=(self.pose3D,), name='Pose_Theading')
        PoseTheading.daemon = True
        PoseTheading.start()
        print("Pose3D Ice Server Up")

        # Thread to serve Navdata with the all navigation info
        print("- navData Ice Server...")
        NavDataTheading = threading.Thread(target=self.openNavdataChannel, args=(self.navdata,), name='Navdata_Theading')
        NavDataTheading.daemon = True
        NavDataTheading.start()
        print("Navdata Ice Server Up")

        print("- Mission Ice Server...")
        # Thread to receieve a mission plan
        MissionTheading = threading.Thread(target=self.openMissionChannel, args=(self.mission,), name='Mission_Theading')
        MissionTheading.daemon = True
        MissionTheading.start()
        print("Mission Ice Server Up")

        #  Open the Extra channel in a thread
        print("- Extra Ice Server...")
        ExtraTheading = threading.Thread(target=self.openExtraChannel, args=(self.extra,), name='Extra_Theading')
        ExtraTheading.daemon = True
        ExtraTheading.start()
        print("Extra Ice Server Up")

\end{python}

Cada hilo abre un servicio Ice, como todos los servicios Ice que implementamos son muy similares podremos como ejemplo de implementación el servicio de Pose3D

\begin{python}[
    basicstyle=\scriptsize, %or \small or \footnotesize etc.
]
    def openPose3DChannel(self, pose3D):
        """
        Open a Ice Server to serve Pose3D objects
        :return: none
        """

        status = 0
        ic = None
        # recovering the attitude
        Pose2Tx = pose3D
        try:
            ic = Ice.initialize(sys.argv)
            adapter = ic.createObjectAdapterWithEndpoints("Pose3DAdapter", "default -p 9998")
            object = Pose2Tx
            # print object.getPose3DData()
            adapter.add(object, ic.stringToIdentity("ardrone_pose3d")) #ardrone_pose3d  Pose3D
            adapter.activate()
            ic.waitForShutdown()
        except:
            traceback.print_exc()
            status = 1
        if ic:
            # Clean up
            try:
                ic.destroy()
            except:
                traceback.print_exc()
                status = 1

        sys.exit(status)

\end{python}
\cleardoublepage
\chapter{AUV Commander}

\section{Arquitectura general} 
\label{sec:arquitectura}




\cleardoublepage
\chapter{Experimentos}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% CONCLUSIONES %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Conclusiones}
\label{chap:conclusiones}


\section{Consecuci\'on de objetivos}
\label{sec:consecucion-objetivos}

Esta secci\'on es la secci\'on espejo de las dos primeras del cap\'itulo de objetivos,
donde se planteaba el objetivo general y se elaboraban los espec\'ificos.

Es aqu\'i donde hay que debatir qu\'e se ha conseguido y qu\'e no. Cuando algo no
se ha conseguido, se ha de justificar, en t\'erminos de qu\'e problemás se han
encontrado y qu\'e medidas se han tomado para mitigar esos problemás.


\section{Aplicaci\'on de lo aprendido}
\label{sec:aplicacion}

Aqu\'i viene lo que has aprendido durante el Grado/M\'aster y que has aplicado
en el TFG/TFM. Una buena idea es poner las asignaturas m\'as relacionadas y
comentar en un p\'arrafo los conocimientos y habilidades puestos en pr\'actica.

\begin{enumerate}
  \item a
  \item b
\end{enumerate}


\section{Lecciones aprendidas}
\label{sec:lecciones_aprendidas}

Aqu\'i viene lo que has aprendido en el Trabajo Fin de Grado/M\'aster.

\begin{enumerate}
  \item a
  \item b
\end{enumerate}


\section{Trabajos futuros}
\label{sec:trabajos_futuros}

Ning\'un software se termina, as\'i que aqu\'i vienen ideas y funcionalidades
que estar\'ia bien tener implementadas en el futuro.

Es un apartado que sirve para dar ideas de cara a futuros TFGs/TFMs.


\section{Valoraci\'on personal}
\label{sec:valoracion}

Finalmente (y de manera opcional), hay gente que se anima a dar su punto de
vista sobre el proyecto, lo que ha aprendido, lo que le gustar\'ia haber aprendido,
las tecnolog\'ias utilizadas y dem\'as.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% AP\'eNDICE(S) %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\appendix
\chapter{Manual de usuario}
\label{app:manual}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% BIBLIOGRAFIA %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage

% Las siguientes dos instrucciones es todo lo que necesitas
% para incluir las citas en la memoria
\bibliographystyle{abbrv}
\bibliography{memoria}  % memoria.bib es el nombre del fichero que contiene
% las referencias bibliogr\'aficas. Abre ese fichero y mira el formato que tiene,
% que se conoce como BibTeX. Hay muchos sitios que exportan referencias en
% formato BibTeX. Prueba a buscar en http://scholar.google.com por referencias
% y ver\'as que lo puedes hacer de manera sencilla.
% M\'as informaci\'on: 
% http://texblog.org/2014/04/22/using-google-scholar-to-download-bibtex-citations/

\end{document}
\grid
\grid
